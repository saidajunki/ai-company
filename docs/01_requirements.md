# 具体要件（Requirements）

## 1. 統治UI: Slack

- 意思決定/相談/報告の主戦場はSlack
- 10分レポート:
  - 宛先: BableTechワークスペースの `C0AF21AFC14`
  - 方式: **毎回新規投稿**
  - 許容: キリが悪ければスキップ可、±5分程度のズレも許容
  - 目的: 展開が速い前提で「いま何が起きていて、残コストと成果は何か」を追えること
- 承認:
  - 承認は **SlackリアクションでOK**
  - 承認依頼メッセージに `request_id` と「✅=承認 / ❌=却下」を明記する

## 2. 予算管理（概算でOK）

- 予算の単位: **直近60分（移動窓）**
- 上限: **$10 / 60分**
- コスト計測の精度:
  - 正確でなくてよい（数万円単位の誤差は許容）
  - まずはトークン数の記録と概算（モデル・単価表にもとづく推定）で開始する

## 3. 人間（Creator）の介入範囲

- 原則として人間がやるのは:
  - 契約/支払い方法の登録/アカウント作成などの「人間でしかできない手続き」
  - それに付随する承認
- それ以外の作業はAIが前提で進める

## 4. 実行環境

- AIエージェントにはVPSサーバー1台を貸し出す
- VPSは基本的にAIが丸ごと管理する
- 複数の会社を立てる可能性があるため、クリーンアップ容易性を優先して隔離環境を使う
  - 採用: **1コンテナ=1会社**（会社に1台PCを渡すイメージ）
  - 原則としてDB等も別コンテナにはせず、必要なら会社コンテナの中で立てる
  - 社長AI（中央管理AI）を含む全エージェントは **会社コンテナ内で生成/稼働** する
  - コンテナ作成後、社長AIの初期起動は人為的に行う（ブートストラップ）
- ドメイン取得とDNSレコード設定は事前に行う
- OpenRouterのAPIキーを共有する
- 中央管理AIは、VPS内で **シェルコマンドを強く活用**する
- `cron` は基本使わない（自律性を優先）
  - ただし「レポートが20分以上来ない」等の監視/叩き起こし用途で使う可能性はある

## 4.1. 既存システムへの非影響

- 既存のVPS上のサービスに影響を与えない（ポート衝突、他スタックのデータ破壊、ディスク枯渇などを避ける）

## 5. 公開方針（原則公開）

- 成果物は基本的に公開する（確認の容易さを優先）
- ただし **APIキー/トークン/支払い情報/個人情報** などの機微情報は公開しない
  - 鍵管理と公開前チェックでリスクを制御する

## 5.1. コードと成果物の置き場所

- **AI会社を動かすためのコード**は、この `ai-company` リポジトリで管理する
- AI会社が作り出した成果物（コード/文章/データ等）は、必要に応じてGitHub等で管理してよい
  - 管理しない（使い捨て）という判断も許容する
  - ただし「後から検証/再現したいもの」は公開アーカイブ（Git等）に残す

## 6. 記憶（カオス防止）

懸念:
- 方向性がブレて手当たり次第に着手する
- 始めたサービスの存在を忘れる/重複する
- 同じことを何度も繰り返す

要件:
- 組織としての意思決定・理念・ルールを残す領域がある
- 「誰がどの役割で動いているか」「どれくらいコストを使っているか」を把握できる
- 「誰にどんなモデルを使うべきか」を管理できる
- 会社憲法の変更は、中央管理AIが提案してよいが **適用はCreator承認が必要**

## 7. 情報の鮮度（カテゴリ固定なし）

- 「必ずWeb検索するカテゴリ」「知識の期限」は固定しない（AIが判断する）
- 代わりに、外部情報は必ず **日付メタデータ** を持つ:
  - `published_at`: 出来事/記事の日時（不明なら不明で扱う）
  - `retrieved_at`: 取得した日時
- 出力では「最近」などの曖昧表現を避け、できる限り日付で語る
  - 2年前のニュースは「2年前の出来事」として扱える状態にする

## 8. 鮮度の高い情報源の多様化

- Web検索だけでなく、鮮度の高い情報源（例: X, Instagram, Googleニュース等）が存在することを前提にする
- ただし、X/Instagram等はAPI利用条件や費用が変わり得るため、必要なら「承認→契約→キー発行→共有」のフローを取る

## 9. ハング/停止の懸念への対策

懸念:
- エージェントがハングして進捗が詰まる
- 生成を終えてしまい、ループせず会社が止まる

要件:
- 10分レポートが20分以上来ない場合、中央管理AIを叩き起こす/再起動する仕組みを用意する
- 監視は「Slack投稿の有無」ではなく、**heartbeatファイル**（例: `companies/<company_id>/state/heartbeat.json`）の更新で判定する（レポートのズレ許容のため）
- 叩き起こしの監視/実行主体は **ホスト側の最小watchdog** とする（会社コンテナがフリーズしても監視が死なない）
- 叩き起こし時はSlackにも通知する（「レポートが止まったので回復を試みる」等）
- コスト上限を超えない限り、異常があっても「停止」ではなく「回復/継続」を基本方針とする
